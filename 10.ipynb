{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58eb038-6505-426b-93ff-3de67de49372",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans:1\n",
    "R-squared, also known as the coefficient of determination, is a statistical measure commonly used in linear regression analysis to evaluate the goodness of fit of a regression model to the observed data. It provides information about how well the independent variable(s) in the model explain the variability in the dependent variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecd2373-6fd6-4c1d-a807-a800ff066f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "Abs:2\n",
    "Adjusted R-squared is a modified version of the regular R-squared that takes into account the number of independent variables (predictors) in a regression model. It addresses a limitation of the regular R-squared, which tends to increase as more independent variables are added to the model, even if those variables do not actually contribute meaningfully to explaining the variability in the dependent variable. Adjusted R-squared provides a more balanced measure of a model's goodness of fit by penalizing the inclusion of unnecessary or redundant predictors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2491566f-8a29-459f-8d1f-71cdbb2f6265",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans:3\n",
    "Adjusted R-squared is more appropriate to use when you are working with regression models that have multiple independent variables (predictors). It addresses some of the limitations of the regular R-squared that can arise when dealing with complex models with many predictors. Here are some scenarios where adjusted R-squared is particularly useful:\n",
    "\n",
    "Model Comparison: When comparing different models with varying numbers of predictors, the adjusted R-squared is more informative. It helps you choose a model that strikes a balance between the goodness of fit and the complexity of the model. Models with higher adjusted R-squared values are generally preferred because they explain more variation in the dependent variable, but you should also consider whether the added complexity is justified.\n",
    "\n",
    "Avoiding Overfitting: Adjusted R-squared penalizes the inclusion of unnecessary predictors in the model. This makes it a useful tool for avoiding overfitting, where a model fits the noise in the data instead of the true underlying relationship. Lower adjusted R-squared values when adding more predictors can signal that the added variables do not contribute enough to justify their inclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e884e7a1-a434-4dfa-9f3c-d89fb8492457",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans:4\n",
    "RMSE (Root Mean Squared Error):\n",
    "RMSE is a measure of the average magnitude of the errors between predicted values and actual values. It gives more weight to larger errors due to the squaring of the differences. RMSE is calculated by taking the square root of the mean of the squared differences between predicted and observed values\n",
    "\n",
    "MSE (Mean Squared Error):\n",
    "MSE is similar to RMSE but without taking the square root. It's the mean of the squared differences between predicted and observed values. Like RMSE, MSE also gives more weight to larger errors.\n",
    "\n",
    "\n",
    "MAE (Mean Absolute Error):\n",
    "MAE measures the average magnitude of the absolute errors between predicted and observed values. Unlike MSE and RMSE, MAE treats all errors equally and does not emphasize large errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee21672a-57de-44d3-b4c5-5cf0f848cafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans:5\n",
    " the choice between RMSE, MSE, and MAE depends on your priorities and the characteristics of your data. RMSE is suitable when you want to give more weight to larger errors, MSE is simple to calculate and aligns with squared error minimization goals, and MAE is more robust to outliers and provides more interpretable error measurements. It's often a good practice to consider multiple metrics and choose the one that best aligns with your objectives and the nature of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f8198a-ec5c-4f82-8cab-c27e8eae779f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans:6\n",
    "Lasso (Least Absolute Shrinkage and Selection Operator) regularization is a technique used in linear regression and other regression-based machine learning algorithms to prevent overfitting and improve the generalization of models. It does so by adding a penalty term to the standard regression objective function that encourages the coefficients of certain features to be exactly zero. This has the effect of shrinking some coefficients to zero, effectively selecting a subset of the most important features while simultaneously regularizing the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54f5cc3-d80c-410f-b04d-c1ef12c3f322",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans:7\n",
    "Regularized linear models help prevent overfitting in machine learning by introducing a penalty term into the model's objective function that discourages excessively complex or intricate models. Overfitting occurs when a model captures not only the underlying patterns in the data but also the noise or random fluctuations. This leads to poor generalization performance on new, unseen data.\n",
    "\n",
    "Regularization adds a constraint to the model's optimization process, encouraging it to find simpler solutions that generalize better to new data. Two common types of regularization are Ridge regularization (L2 regularization) and Lasso regularization (L1 regularization), both of which modify the linear regression objective function by penalizing the magnitude of the coefficients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1a0ae5-883d-4519-a29d-d061a412dfff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
